{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson distribution Shenanigans\n",
    "\n",
    "https://towardsdatascience.com/an-illustrated-guide-to-the-poisson-regression-model-50cccba15958"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from patsy import dmatrices\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import poisson\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting patsy\n",
      "  Downloading https://files.pythonhosted.org/packages/ea/0c/5f61f1a3d4385d6bf83b83ea495068857ff8dfb89e74824c6e9eb63286d8/patsy-0.5.1-py2.py3-none-any.whl (231kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 2.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting statsmodels\n",
      "  Downloading https://files.pythonhosted.org/packages/cb/83/540fd83238a18abe6c2d280fa8e489ac5fcefa1f370f0ca1acd16ae1b860/statsmodels-0.11.1-cp36-cp36m-manylinux1_x86_64.whl (8.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 8.7MB 168kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.4 in /home/heath/Projects/politics/trump_tweets/lib/python3.6/site-packages (from patsy)\n",
      "Requirement already satisfied: six in /home/heath/Projects/politics/trump_tweets/lib/python3.6/site-packages (from patsy)\n",
      "Requirement already satisfied: pandas>=0.21 in /home/heath/Projects/politics/trump_tweets/lib/python3.6/site-packages (from statsmodels)\n",
      "Requirement already satisfied: scipy>=1.0 in /home/heath/Projects/politics/trump_tweets/lib/python3.6/site-packages (from statsmodels)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/heath/Projects/politics/trump_tweets/lib/python3.6/site-packages (from pandas>=0.21->statsmodels)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/heath/Projects/politics/trump_tweets/lib/python3.6/site-packages (from pandas>=0.21->statsmodels)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "Successfully installed patsy-0.5.1 statsmodels-0.11.1\n"
     ]
    }
   ],
   "source": [
    "#!{sys.executable} -m pip install patsy statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tweets\n",
    "df = utils.rdt_tweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get daily counts\n",
    "by_day = df.groupby(df.index.date).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get last year of data\n",
    "year_date = by_day.iloc[len(by_day)-1].name - datetime.timedelta(days=365)\n",
    "by_day_year = by_day[year_date:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Training Data\n",
    "\n",
    "We'll do it this way for now, but in the future, it will be a different split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data set length=294\n",
      "Testing data set length=72\n"
     ]
    }
   ],
   "source": [
    "mask = np.random.rand(len(by_day_year)) < 0.8\n",
    "df_train = by_day_year[mask]\n",
    "df_test = by_day_year[~mask]\n",
    "print('Training data set length='+str(len(df_train)))\n",
    "print('Testing data set length='+str(len(df_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super fucking basic poisson\n",
    "\n",
    "tiers: \n",
    "```\n",
    "prior_counts = {\n",
    "  \"149\" : sum(by_day[\"sum_7\"] <= 149),\n",
    "  \"150-159\" : sum((by_day[\"sum_7\"] >= 150) & (by_day[\"sum_7\"] < 160)),\n",
    "  \"160-169\" : sum((by_day[\"sum_7\"] >= 160) & (by_day[\"sum_7\"] < 170)),\n",
    "  \"170-179\" : sum((by_day[\"sum_7\"] >= 170) & (by_day[\"sum_7\"] < 180)),\n",
    "  \"180-189\" : sum((by_day[\"sum_7\"] >= 180) & (by_day[\"sum_7\"] < 190)),\n",
    "  \"190-199\" : sum((by_day[\"sum_7\"] >= 190) & (by_day[\"sum_7\"] < 200)),\n",
    "  \"200-209\" : sum((by_day[\"sum_7\"] >= 200) & (by_day[\"sum_7\"] < 210)),\n",
    "  \"210-219\" : sum((by_day[\"sum_7\"] >= 210) & (by_day[\"sum_7\"] < 219)),\n",
    "  \"220\" : sum(by_day[\"sum_7\"] >= 220)\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "196\n"
     ]
    }
   ],
   "source": [
    "mu = int(df_train[\"ID\"].mean().round())\n",
    "\n",
    "week = mu * 7\n",
    "print(week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = poisson(week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_likelihoods = {\n",
    "    \"149<\":rv.cdf(149),\n",
    "    \"150-159\":rv.cdf(159) - rv.cdf(149),\n",
    "    \"160-169\":rv.cdf(169) - rv.cdf(159),\n",
    "    \"170-179\":rv.cdf(179) - rv.cdf(169),\n",
    "    \"180-189\":rv.cdf(189) - rv.cdf(179),\n",
    "    \"190-199\":rv.cdf(199) - rv.cdf(189),\n",
    "    \"200-209\":rv.cdf(209) - rv.cdf(199),\n",
    "    \"210-219\":rv.cdf(219) - rv.cdf(209),\n",
    "    \"220>\":1 - rv.cdf(220)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'149<': 0.00027482576838815776,\n",
       " '150-159': 0.003376058328624801,\n",
       " '160-169': 0.02340681808394423,\n",
       " '170-179': 0.09122212041226974,\n",
       " '180-189': 0.20630753064510746,\n",
       " '190-199': 0.27841963162602085,\n",
       " '200-209': 0.22979595015869514,\n",
       " '210-219': 0.1185671641686934,\n",
       " '220>': 0.04208432731798306}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekly_likelihoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00027482576838815776"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv.cdf(149)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.003376058328624801"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rv.cdf(159) - rv.cdf(149)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And for a given day\n",
    "\n",
    "Currently there is a day and 3 hours left and he already has 192 tweets. Let's assume he tweets for 20 hours out of the day, so 3 hours is 0.15, let's round up to 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<149': 0.0,\n",
       " '150-159': 0.0,\n",
       " '160-169': 0.0,\n",
       " '170-179': 0.0,\n",
       " '180-189': 0.0,\n",
       " '190-199': 2.695165634942316e-12,\n",
       " '200-209': 2.4895526421990978e-05,\n",
       " '210-219': 0.02803483294672782,\n",
       " '>220': 0.9567073249868225}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = df_train[\"ID\"].mean()\n",
    "days_left = 1.2\n",
    "tweets_so_far = 197\n",
    "\n",
    "def difference_dist(rv, upper, lower, tweets_so_far):\n",
    "    adj_upper = upper - tweets_so_far\n",
    "    adj_lower = lower - tweets_so_far\n",
    "    \n",
    "    return rv.cdf(adj_upper) - rv.cdf(adj_lower)\n",
    "\n",
    "def remaining_odds(mu, days_left):\n",
    "    likelihoods = dict()\n",
    "    \n",
    "    adj_mu = int(round(mu * days_left))\n",
    "    \n",
    "    rv = poisson(adj_mu)\n",
    "    \n",
    "    # add the lower bound to it\n",
    "    likelihoods[\"<149\"] = rv.cdf(149-tweets_so_far)\n",
    "    \n",
    "    likelihoods[\"150-159\"] = difference_dist(rv, 159, 150, tweets_so_far)\n",
    "    likelihoods[\"160-169\"] = difference_dist(rv, 169, 160, tweets_so_far)\n",
    "    likelihoods[\"170-179\"] = difference_dist(rv, 179, 170, tweets_so_far)\n",
    "    likelihoods[\"180-189\"] = difference_dist(rv, 189, 180, tweets_so_far)\n",
    "    likelihoods[\"190-199\"] = difference_dist(rv, 199, 190, tweets_so_far)\n",
    "    likelihoods[\"200-209\"] = difference_dist(rv, 209, 200, tweets_so_far)\n",
    "    likelihoods[\"210-219\"] = difference_dist(rv, 219, 210, tweets_so_far)\n",
    "\n",
    "    likelihoods[\">220\"] = 1 - rv.cdf(220-tweets_so_far)\n",
    "    \n",
    "    return likelihoods\n",
    "    \n",
    "remaining_odds(mu, days_left)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (trump_tweets)",
   "language": "python",
   "name": "trump_tweets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
